{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ca2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b15f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_copy_files(source_subdir, train_subdir, validation_subdir, test_size=0.2):\n",
    "    files = [f for f in os.listdir(source_subdir) if os.path.isfile(os.path.join(source_subdir, f))]\n",
    "    train_files, validation_files = train_test_split(files, test_size=test_size)\n",
    "    \n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(source_subdir, file), os.path.join(train_subdir, file))\n",
    "    \n",
    "    for file in validation_files:\n",
    "        shutil.copy(os.path.join(source_subdir, file), os.path.join(validation_subdir, file))\n",
    "\n",
    "dataset_dir = \"C:/Users/Admin/Desktop/Uni/GIN515/dataset/\"\n",
    "train_dir = \"C:/Users/Admin/Desktop/Uni/GIN515/training/\"\n",
    "validation_dir = \"C:/Users/Admin/Desktop/Uni/GIN515/validation/\"\n",
    "\n",
    "# Directories for 'with_mask' and 'without_mask'\n",
    "subdirs = ['with_mask', 'without_mask']\n",
    "\n",
    "# Ensure the main and subdirectories exist\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(os.path.join(train_dir, subdir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(validation_dir, subdir), exist_ok=True)\n",
    "\n",
    "# Process each subdirectory\n",
    "for subdir in subdirs:\n",
    "    source_subdir = os.path.join(dataset_dir, subdir)\n",
    "    train_subdir = os.path.join(train_dir, subdir)\n",
    "    validation_subdir = os.path.join(validation_dir, subdir)\n",
    "\n",
    "    split_and_copy_files(source_subdir, train_subdir, validation_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "136e912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3924 images belonging to 2 classes.\n",
      "Found 2650 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      " 34/246 [===>..........................] - ETA: 39s - loss: 0.5775 - acc: 0.7096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 71s 286ms/step - loss: 0.2995 - acc: 0.8756 - val_loss: 0.2144 - val_acc: 0.9279\n",
      "Epoch 2/5\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 0.1570 - acc: 0.9422 - val_loss: 0.0976 - val_acc: 0.9626\n",
      "Epoch 3/5\n",
      "246/246 [==============================] - 47s 189ms/step - loss: 0.0976 - acc: 0.9661 - val_loss: 0.0637 - val_acc: 0.9770\n",
      "Epoch 4/5\n",
      "246/246 [==============================] - 46s 186ms/step - loss: 0.0468 - acc: 0.9839 - val_loss: 0.0264 - val_acc: 0.9925\n",
      "Epoch 5/5\n",
      "246/246 [==============================] - 44s 180ms/step - loss: 0.0361 - acc: 0.9862 - val_loss: 0.0387 - val_acc: 0.9849\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                           input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=16,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(128, 128))\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                    batch_size=16,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(128, 128))\n",
    "\n",
    "\n",
    "history = model.fit(train_generator, epochs=5, validation_data= validation_generator)\n",
    "\n",
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c60da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the Haar Cascade for face detection\n",
    "cascade_path = r\"C:\\Users\\Admin\\Downloads\\haarcascade_frontalface_default.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (128, 128))  # Resize to the expected input size of the model\n",
    "        face_roi = face_roi / 255.0  # Normalize pixel values if needed\n",
    "        face_roi = np.expand_dims(face_roi, axis=0)  # Add the batch dimension\n",
    "\n",
    "        prediction = model.predict(face_roi)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        threshold = 0.4  \n",
    "        if prediction > threshold:\n",
    "            cv2.putText(frame, 'Mask', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, 'No Mask', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e39da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
